Name: Hasibur Rahman Headline: Software Engineer || PHP | Javascript | Reactjs | RDBMS | REST API Location: Gazipur District, Dhaka, Bangladesh Current Company: Walton Hi-Tech Industries PLC. About: # I always try to be better than the one that I was yesterday as a human and as an Engineer. # I love to explore new technologies and try to implement what I am thinking. # Solving problems always interested me whether it is personal or professional. # I believe programming is my flag, and any language is my weapon, and I love to conquer. My first and favorite weapon is C and C++, right now using PHP and JavaScript. Top Skills: C, C++ Featured Section: - Indeed Resume: Resume (Link: https://www.linkedin.com/in/hasibur1777/overlay/1635488094105/single-media-viewer?type=LINK&profileId=ACoAACpX-dUBhJ1ksLo_csIHcFrAQXD1TpGWbKk) - HRahman1777 - Github: (Link: https://github.com/HRahman1777) - The ICPC International Collegiate Programming Contest: Asia Dhaka Regional Site Online Preliminary Contest (Link: https://www.linkedin.com/in/hasibur1777/overlay/1635480014978/single-media-viewer?type=LINK&profileId=ACoAACpX-dUBhJ1ksLo_csIHcFrAQXD1TpGWbKk) Experience: - Walton Hi-Tech Industries PLC. at 3 yrs 4 mos (None, Chandra, Kaliakoir, Gazipur, Aug 2024 - Present ¬∑ 1 yr 3 mos): N/A Education: - Master of Science - MS, Computer Science from Jahangirnagar University ‡•§ ‡¶ú‡¶æ‡¶π‡¶æ‡¶ô‡ßç‡¶ó‡ßÄ‡¶∞‡¶®‡¶ó‡¶∞ ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º (Sep 2023, Grade: N/A) - Bachelor of Science - BS, Computer Science from Daffodil International University-DIU (Jan 2018 - Dec 2021, Grade: N/A) Projects: - Footsteps (Apr 2022 - Jun 2022): N/A - Word-Filter (Mar 2022 - Mar 2022): N/A Interests: - Clement Mihailescu (516,000 followers) - LinkedIn (32,246,177 followers) - Google (39,428,235 followers) - Developers, Engineers & Techies: Solidity, Rust, C++, C#, Python, Java, Javascript | Blockchain (834,243 members) - Go Developer Community (GoLang) (44,796 members) - SELISE Highlights for 2025 (Published monthly) - Code & Beyond: WellDev Pulse (Published weekly) - freeCodeCamp (2,139,146 followers) - Daffodil International University-DIU (102,966 followers) Posts: Post 1: üöÄ I‚Äôm hiring Deployed Engineers at LangChain. I‚Äôm looking for people who can code like engineers and communicate like partners. Builders who love solving complex problems and working directly with customers. We're building an elite team of deeply technical, customer obsessed folks. If you‚Äôre excited about deploying real LLM and agent systems in production, let‚Äôs talk. Reach out over DM or apply here! https://lnkd.in/gNE2VYut Images: None Post 2: I haven't written a line of code in over a year. My output has 10x'd. This is what happens when you stop thinking about coding agents tools as copilots and start treating them as Deep Agents. What nobody tells you is most people are using these tools wrong üòâ - They're still writing code with AI instead of through AI. - They haven't learned Context Engineering or created custom slash commands to automate their processes. - They're not leveraging multiple background agents that scale work while they think. - They don't understand the taxonomy of autonomy‚Äîfrom L0 (manual) to L4 (full YOLO mode). We're running a track at Google Cloud Day where you'll see exactly how Agentic Coding works in real development workflows. Real systems. Real teams. Real ROI. We'll see production stacks in action. We'll break down best practices for working with Coding Agents, explore how they're implemented within the Deep Agents framework, and discuss: what they can do what they can't what they shouldn't üôÇ With incredible speakers from: monday.com , Qodo , LangTalks , Wix , Wiz , Tenzai we're going to understand the fundamental shift in how software gets built. See you there :) (Link for event + agenda in the comments) Images: https://media.licdn.com/dms/image/v2/D4D22AQH0IaqdXVkJTQ/feedshare-shrink_800/B4DZpKLLjhIkAg-/0/1762181038060?e=1764201600&v=beta&t=SLbMyUfgHfmQEdOuXmeRDMRucmbqyHqOWvrNLxXRC1s Post 3: Your AI agent has dementia. LangChain just dropped the cure: DeepAgents CLI with actual persistent memory. This project solves the most infuriating problem in AI development, agents that forget everything the moment you close your terminal. It gives your AI assistant an actual memory that persists across sessions. Key Features: ‚úÖ True persistent memory Your agent writes markdown notes to ~/.deepagents/memories/ and reads them before every response. Like a human taking notes. ‚úÖ File operations that work: Read, write, and edit files in your project with diff previews and human approval. No more "I can't access your filesystem." ‚úÖ Shell command execution Run tests, install packages, deploy code - all with your permission. Because we're not insane. ‚úÖ Multi-agent personalities Create specialized agents (backend-dev, frontend-wizard, devops-guru) each with their own memory and expertise. Getting started is stupidly simple. Just install and run: pip install deepagents-cli && deepagents Harrison said they built this because copy-pasting context 47 times a day is insanity (we agree). Check out the code, see the full toolset, and contribute on GitHub! ‚ôªÔ∏è Repost if you're done being your AI's memory bank Images: https://media.licdn.com/dms/image/v2/D5622AQEqXYUNyqPQHA/feedshare-shrink_800/B56ZphdasqH8Ag-/0/1762571693340?e=1764201600&v=beta&t=vamnsTwPbvsyxACT7zilpU9h7vwdmE-5BZZtBy1woXw Post 4: New Chat LangChain just dropped (Now Faster, Smarter, and Better Looking)! Who needs docs when you can just chat? We rebuilt Chat LangChain completely from scratch to make it faster, smarter, and more accurate. Now you can ask questions about LangChain, LangGraph, and LangSmith‚Äîand get instant answers from our complete documentation and knowledge base. The goal? Help developers ship faster by making it easier to get the answers they need without digging through docs. Whether you're debugging, exploring features, or architecting a complex system, you get the context you need instantly. Try it out: https://chat.langchain.com Want to see how we built it? Read the full breakdown: https://lnkd.in/eg5wmUxe hashtag # LangChain hashtag # AI hashtag # DeveloperTools hashtag # BuildInPublic hashtag # LLM Images: None Post 5: üöÄMini "TypeScript AI" release day! We released a bunch of things in the Lang* ecosystem to make building AI agents in TypeScript easier than ever: ü§ñDeepAgents 1.0: https://lnkd.in/gCm_NUff üï∏Ô∏èTutorial on building agents with NextJS: https://lnkd.in/gh9YYkD6 üìÉTutorial on building a deep research agent with DeepAgents TypeScript: https://lnkd.in/gTix6suB Images: https://media.licdn.com/dms/image/v2/D5622AQHJn3ZxSy2p7Q/feedshare-shrink_800/B56Zpa6HlAI0Ag-/0/1762461776982?e=1764201600&v=beta&t=qp6YuHM5ZA-VN2T_JpKD6KJ7DGggzvdvEnC4k2QvjL4 Post 6: Today we're releasing 0.2 of deep agents üìÅThe main addition here is a "backend" abstraction, which allows you to swap out the filesystem that deep agents use. Can be local filesystem, a database, remote vm, anything Agent Harnesses like deep agents are becoming more important as models become good enough to build more complex, autonomous agents. We wrote a bit about why and how we're doubling down on deep agents: https://lnkd.in/g5SU9JnA Images: https://media.licdn.com/dms/image/v2/D5622AQHcIzlw6bYwVw/feedshare-shrink_800/B56ZoryJvgKAAk-/0/1761671159982?e=1764201600&v=beta&t=G2g2D2EP1RTmsEG9iTejdO99HCVh7TYNpLKODpHaM8k Post 7: ü§ñAgent Framework vs Runtime vs Harness A term I've heard recently is agent "harness". We're building DeepAgents to be that I wrote a blog on my interpretation of that term and how it differs from "framework" (LangChain) and "runtime" (LangGraph) https://lnkd.in/gZuqJS97 Images: https://media.licdn.com/dms/image/v2/D5622AQFaDTflLJDcfA/feedshare-shrink_800/B56ZocK6L3I8Ag-/0/1761409213844?e=1764201600&v=beta&t=aeOJKhiNKrHcfeJXCS_tufG2jiofdamNiEjlK7UnktA Post 8: ‚ÄúProbably a lot of what we currently do in engineering is now wrong ‚Äì and we don‚Äôt realize it yet.‚Äù That line from Fergal Reid (PhD) (Chief AI Officer, Intercom , building Fin.ai ) set the tone at our Fin √ó LangChain meetup in Amsterdam. Together with Marco Perini (Deployed Engineer, LangChain), they unpacked what it really takes to build AI Agents that work in production, and why building trust in these systems requires as much discipline and iteration as innovation. From early hand-coded loops to fine-tuned custom models and real-world reliability, the conversation showed just how fast the field is evolving ‚Äî and what it takes to keep up. Watch the highlights below, and see why this moment in AI feels like the start of something bigger. üëá Subscribe on Luma to join the next Fin meetup. Images: None Post 9: Today was our penultimate session: Agents! ü§ñ Catch up with the recording here: https://lnkd.in/gmxPnXqz We covered: * What's an agent? üõ†Ô∏è Tool calling in a loop üîÅ * Building a standard agent with agent-framework * Supervisor agent architecture with subagent * Similar agent setup for langchain and pydantic-ai * Agentic workflows with agent-framework and visualization with devui * Agentic workflows with Langgraph and visualization in Langsmith * Human-in-the-loop with Langchain's Agent Inbox * Agent planning and memory Slides here: https://lnkd.in/g5grKt7v Let me know if you'd want a deeper dive into any agent topics in future live stream series! Images: https://media.licdn.com/dms/image/v2/D5622AQHtgvqXqrb4WA/feedshare-shrink_800/B56ZoPfZ8JHAAk-/0/1761196483747?e=1764201600&v=beta&t=4HCQlqdJIWDFbob-xVFlx_CJvXf-8CqIe63bS4F55Ak Post 10: Created an interactive webpage to showcase the milestones achieved by LangChain and LangGraph v1.0. Take a look! üòä https://lnkd.in/eh_r-FEq Images: None Post 11: Bring me your best demand gen people! I'm hiring. This is going to be an awesome role because we are so early in our marketing programs. We do a lot of community and field, but the follow up is nearly non existent, we have 0 paid programs going, we don't really do "campaigns" yet. And, because of the education flywheel the team is running, we're still growing an insane amount. Greenfield for 0-1 repeatable programs + partnering with our applied AI eng team is huge. Come join us! Images: None Post 12: Most agent frameworks fall short when it comes to customization beyond the core agent loop (a model with a prompt, calling tools). LangChain V1 (alpha out now!) introduces a new concept of agent middleware that enables hooking into this loop at every step. üìÇ before_agent ‚Äî Load files, validate input ‚úÇÔ∏è before_model ‚Äî Summarize convos, trim messages ‚ôªÔ∏è wrap_model_call ‚Äî Dynamic prompts, model, tools üõ†Ô∏è wrap_tool_call ‚Äî Tool retries, error handling üßë after_model ‚Äî Human in the loop üõ°Ô∏è after_agent ‚Äî Save results, final guardrails Plus, new docs: https://lnkd.in/ejusf3AP ! Images: https://media.licdn.com/dms/image/v2/D4E22AQFGeh2ioO3TMA/feedshare-shrink_1280/B4EZnjvYLsK0As-/0/1760462472487?e=1764201600&v=beta&t=ECiEoqjSCdpnWvlUDYfdyVR-0t-4DWHYW9ugCmyQGco Post 13: With the new createAgent() abstraction, you can finally see üëÄ and shape üéõÔ∏è how your agents think and act. LangChain now supports middleware hooks that let you intercept, observe, or modify every step of an agent‚Äôs reasoning loop: üß† beforeAgent / afterAgent ‚Äì pre- and post-invocation logic üí¨ beforeModel / afterModel ‚Äì wrap or monitor model calls üß∞ wrapToolCall ‚Äì control how tools are executed ‚öôÔ∏è wrapModelCall ‚Äì add retries, caching, or fallbacks That means you can now: - add human-in-the-loop approvals üôã - summarize long conversations or tool results üßæ - redact PII üîí - switch models or prompts dynamically ‚ö°Ô∏è - or even limit tool calls to prevent runaway costs üí∏ Think of it as plugins for your AI agents ‚Äî as flexible and composable as in Vite, Express.js or Next.js, but for reasoning loops instead of HTTP requests. Stay tuned ‚Äî the LangChain v1 release is just around the corner, and this is only the beginning. Test it out üëâ npm install langchain@alpha Read more about it in our new docs üëâ https://lnkd.in/gP5Us3zd hashtag # LangChain hashtag # AIagents hashtag # middleware hashtag # javascript hashtag # openai hashtag # anthropic hashtag # aiengineering Images: https://media.licdn.com/dms/image/v2/D5622AQFTbdGtsH9DKQ/feedshare-shrink_800/B56ZnkPfQ.KIAk-/0/1760470890013?e=1764201600&v=beta&t=--IOjF9DCc5jcx8LPFR_hd6vU9tks4moTxsA_FDwGrs Post 14: Crazy to surpass OpenAI in package downloads Images: https://media.licdn.com/dms/image/v2/D5622AQGEEROEdL42PQ/feedshare-shrink_800/B56ZnWS7YLHUAg-/0/1760236910925?e=1764201600&v=beta&t=m6RGa_DVRhOWjeLPvfkkFJEPCHvYxAuGByHbPUPvWO0 Post 15: I am not excited about visual workflow builders 1. Not simple enough for the average user. I believe there should be a simpler way to create, modify, and adapt no-code agents 2. Not scalable for complex use cases Wrote a little blog: https://lnkd.in/gDV8pECM Images: https://media.licdn.com/dms/image/v2/D5622AQEAUeMlUKAEmg/feedshare-shrink_800/B56Zm_kVWXHQAg-/0/1759855598998?e=1764201600&v=beta&t=fykB599c6EaRJu0GuyvROq-AZ9ZMPvWt8M4U81UkJBE Post 16: fun to share the stage with Mu Han ( Zoom ) and Michele Catasta ( Replit ) at the Fellows Forum to talk about building agents! shout out to Alex Ren at Fellows Fund for hosting Images: https://media.licdn.com/dms/image/v2/D5622AQGAsY8CurZl_Q/feedshare-shrink_800/B56ZmgyFXyIAAg-/0/1759339110936?e=1764201600&v=beta&t=qH5UlD8-PMqm4viZd9Ycrzx9Glf9yiQQ1aGC7BgD6No Post 17: OpenFunnel (YC F24) is the Search Engine for GTM. Searching for "B2B SaaS, 501-1000 employees, uses Salesforce" is just commoditized and targeted spam. OpenFunnel is a time-aware search engine for insights and activities in your target segment - that reveal pain. You can search for activities like: "Find companies looking to implement usage-based billing" "Find companies that moved from OpenAI to self-hosted models in the last 3-6 months" "Find companies who updated their pricing page to introduce an enterprise plan in the last 3 months" OpenFunnel continuously monitors these time-based signals, delivering actionable insights daily, giving you the fastest, unique insights that your competitors miss out on. Over 1000+ users are already discovering prospects through pain-first search, including some of the fastest-growing companies like Central, Mintlify, and Everest Systems. Congrats on the launch, Fenil Suchak and Aditya Lahiri ! https://lnkd.in/gP3yJ7pR Images: None Post 18: üß† Solving the Memory Problem: Introducing LangChain's Summarization Middleware in LangChain v1 alpha! Ever built an AI agent that "forgets" important context when conversations get too long? You're not alone. Token limits are one of the biggest challenges in building production-ready AI applications. The Problem: Long conversations hit token limits, forcing you to either: ‚ùå Truncate early messages (losing context) ‚ùå Manually manage conversation history ‚ùå Accept degraded performance as context grows The Solution: LangChain's new summarizationMiddleware automatically manages conversation memory by intelligently summarizing older messages while preserving recent context. Why This Matters: ‚úÖ Zero Manual Work - Automatic token monitoring and summarization ‚úÖ Smart Preservation - Never breaks AI/Tool message pairs ‚úÖ Context Continuity - Maintains conversation flow seamlessly Real Impact: Our example shows a conversation going from ~6,000 tokens down to ~1,500 tokens (75% reduction!) while maintaining all the essential context. The agent can still reference earlier challenges and recommendations perfectly. Perfect for: üéØ Customer support chatbots with long sessions üéØ Code review assistants processing large codebases üéØ Research agents analyzing extensive documents üéØ Any multi-turn dialogue that needs persistent memory This isn't just about staying under token limits‚Äîit's about building agents that can have truly long-form, meaningful conversations without losing their memory. üìö Read more in our new docs: https://lnkd.in/gdUW_aPS What's your biggest challenge with conversation memory in AI applications? hashtag # AI hashtag # LangChain hashtag # MachineLearning hashtag # Chatbots hashtag # AgentDevelopment hashtag # OpenAI hashtag # Anthropic hashtag # agents Images: https://media.licdn.com/dms/image/v2/D5622AQHCDIHRXkAQYg/feedshare-shrink_2048_1536/B56ZlTZmh9HUA0-/0/1758040846746?e=1764201600&v=beta&t=yogKzz5lw3h77K7Mt0-mXRs_72LFhqY3WWSB7wuvBQE Post 19: LangChain's Agent Middleware is here! üöÄ Developers need more control over agent behavior for optimal context engineering. LangChain 1.0's new middleware gives you that control while keeping the core agent loop simple (model x tools). Our latest release comes with a few builtin primitives, including: üíÅ‚Äç‚ôÇÔ∏è Human-in-the-loop: get user feedback (approve, modify, deny) before executing expensive or risky tools üèñÔ∏è Summarization: summarize message history to avoid context overflow for long conversations üß± Anthropic prompt caching: optimize cost for long and repetitive prompts Blog: https://lnkd.in/eGrJWE_z Docs: https://lnkd.in/ejusf3AP Images: None Post 20: ü§ùAdding human-in-the-loop to deep agents Many tools that you may want to give to agents will take actions in the real world. For these tools, you will often want to add "human-in-the-loop" steps - require a human user to approve, edit, or respond to their request to execute that tool. In this video, we will see how to add and use human-in-the-loop functionality to Deep Agents Video: https://lnkd.in/gfbjdABH Deep Agents Github: https://lnkd.in/gWpaj88j Images: https://media.licdn.com/dms/image/v2/D5622AQG_8Xf4OGjPHQ/feedshare-shrink_800/B56ZlOlrVbJsAk-/0/1757960124881?e=1764201600&v=beta&t=4_V04OocF4jIi9ud0RZEBLL_VzPV0Ka8v6tGXsWOFxM Post 21: Langchain v1 now has the concept of "middleware" for agents - hooks to run before or after the LLM call. One way to use middleware is to limit the number of tool calls that an agent can make. Agents love to make excessive tool calls, especially when researching, and they don't always need those calls - or, you can't always afford the time or token cost to make them. üíµ ‚è≥ I made ToolCallLimitMiddleware for my issue-triager-agent, which detects when the number of tool calls is over the limit, then removes tools from the agent and tells the agent that it's time to finish up. This middleware is particularly useful when I'm using models with lower rate limits, as I can easily lower their tool call limit. Images: https://media.licdn.com/dms/image/v2/D5622AQFtwC-EV9HY6g/feedshare-shrink_800/B56Zk.xKgYI4Ak-/0/1757694700073?e=1764201600&v=beta&t=umT3ycH8JBbsRQgpAUz44WQ2SmeSrDncwKlULgXVhZY, https://media.licdn.com/dms/image/v2/D5622AQGQG_eS8QIXhg/feedshare-shrink_800/B56Zk.xKg_G4Ag-/0/1757694700190?e=1764201600&v=beta&t=LoPlnKGHOo-X9AWDZVm9Js0a8MVnkLelF2Xv73M-MhE Post 22: Super excited to share the report our summer intern, Aliyan Ishfaq , has been working on! üéâ He explored what it takes to turn Claude Code (or any agent) into an expert on domain-specific tasks, like writing LangGraph code. Check out the blog post for the methods that worked best, why they worked, and how you can apply them to make Claude Code an expert in your domain: https://lnkd.in/gEjecgP2 Images: https://media.licdn.com/dms/image/v2/D5622AQEpcJYbub7p4w/feedshare-shrink_800/B56Zk5tdElHMAg-/0/1757609841352?e=1764201600&v=beta&t=ZMWQY6vcqEC-AUFtlOJt26gqjNN8vhEoNuTI6BCFaxk Post 23: Really good overview of our new human in the loop middleware! We‚Äôll be adding a lot of different types of middleware over next few weeks Images: https://media.licdn.com/dms/image/v2/D5622AQHedsl8EidqLA/feedshare-shrink_800/B56Zk5yggwKIAg-/0/1757611166781?e=1764201600&v=beta&t=q74oVC7yUR88of8OPbf0yfXaGAlUPJXUeOMLpsfovR4 Post 24: Demo video of my Issue Triager Agent: https://lnkd.in/gURN4ASJ LangGraph + AgentInbox (both from LangChain ) + GitHub API + Azure OpenAI gpt-5-mini The agent can mark issues as closed, add/remove labels, and post comments, but it only makes those changes *after* human review! I am really loving the Langsmith traces for seeing what my agent is doing, and AgentInbox for editing and approving the proposed actions. Check out the code at: https://lnkd.in/gSN9swwC I'll also be demo'ing this at the LangChain demo night in SF this week, so let me know if you have ideas for ways to improve it before then. Or a snappier name! Images: None Post 25: üöÄ Big news for AI agent builders: Agent Reinforcement Trainer (ART) now integrates seamlessly with ü¶úüîó LangGraph! If you‚Äôve ever built multi-step, ReAct-style agents, you know the pain: endless prompt tweaking, fragile reasoning, and lots of manual trial-and-error. With this new integration, you can now train your LangGraph agents with reinforcement learning ‚Äî making them smarter, more adaptive, and more efficient over time. ‚ú® What this means in practice: * Agents learn to reason through multi-step problems without hand-holding * They improve tool usage automatically (no more prompt spaghetti) * They make smarter decisions in complex workflows * Training is scalable and robust, powered by ART‚Äôs reinforcement engine And the best part? It‚Äôs a drop-in upgrade: * Swap in ART‚Äôs init_chat_model and wrap_rollout * All interactions, tool calls, and reasoning chains get logged automatically * Plug straight into ART‚Äôs RULER reward function for training ‚Äî no custom rewards needed üí° Imagine your LangGraph prototypes evolving into production-ready agents that actually get better with use. That‚Äôs the power of combining LangGraph‚Äôs agent framework with ART‚Äôs reinforcement learning. üëâ Full docs & examples here: https://lnkd.in/gwWj-xxx Can‚Äôt wait to see what the community builds with this. If you‚Äôre experimenting with multi-step AI agents, give your agents the ability to learn from experience! Images: None Post 26: This is the EASIEST way to build multi-agent systems these days. I'm not kidding. I just built a complex AI system with 3 specialized agents in 20 minutes. An open source event hunter - finds your perfect tech events in 60 seconds. No more endless Google searches. No more missing CFP deadlines. No more outdated event sites. All thanks to Harrison Chase 's new DeepAgents library ü§Ø Here's how RIDICULOUSLY EASY this was: 3 lines of code, system prompts, connection to Bright Data 's MCP. That's it. from deepagents import create_deep_agent agent = create_deep_agent( tools=mcp_tools, instructions="Find tech events", subagents=[search_agent, details_agent] ) BOOM. Multi-agent system is up and running. The secret sauce? DeepAgents is built on Claude Code's architecture - the same system that makes Anthropic's AI so powerful (see the post photo). The genius "Todo list tool" that doesn't actually DO anything - just pure context engineering to keep agents focused until task completion. Setting up my 3 agents was STUPID SIMPLE: Search Agent - "Find events using search engines" Analysis Agent - "Extract event details from URLs" Orchestrator - "Coordinate everything" That's literally the entire architecture definition. The agent literally talks to itself through todos. Keeps perfect focus. Never gets distracted. Seriously - if you've been intimidating by multi-agent systems, those days are OVER. This changes everything about building complex AI workflows. The future isn't one AI doing everything poorly. It's specialized AI teams working together brilliantly. And now it's EASY to build. Try it yourself: https://lnkd.in/dUD6JNjJ See it in action: https://lnkd.in/dZaxe6GB Technical walkthrough: https://lnkd.in/dnUBuf8p What would you build if multi-agent systems were this simple? hashtag # AI hashtag # DeepAgents hashtag # MultiAgent hashtag # LangChain hashtag # TechEvents hashtag # Python hashtag # OpenSource hashtag # MachineLearning hashtag # Hackathons hashtag # WebScraping Images: https://media.licdn.com/dms/image/v2/D4D22AQHoWm32nEernQ/feedshare-shrink_800/B4DZjhmUx4GkAg-/0/1756131578010?e=1764201600&v=beta&t=oal3XqL61IHfvCdbYyVaSg6j-bVFM5gKOndbrZdZbkw Post 27: Continuing my gentle foray into LangChain 's Deepagents framework, I went through the super basic example that Harrison Chase talks about in his intro video ( https://lnkd.in/gzw6VWkh ) and added a couple of minor changes:: * A Wikipedia tool * Using a faster deterministic model for the critique sub-agent (Claude Haiku 3.5, as opposed to Claude Sonnet 4.0 for the main research agent) In this video, you can see how we can build and launch a simple deepresearch agentic query via the DeepAgents UI, and see the traces in Langgraph. Note: Research queries take quite a long time, so the video only shows the beginning of the process. I will make a proper video if I get around to building a more interesting custom deepagents implementation. The code can be found here: https://lnkd.in/gRXUFRx5 References:: * https://lnkd.in/grD4UcPN * https://lnkd.in/gVDFmdFq hashtag # langchain hashtag # deepagents hashtag # llms hashtag # generativeai hashtag # python Images: None Post 28: Quick poll: when you think of `langchain` the python/js package, what do you think of? Images: None Post 29: LangChain Ambassador Ivan Reznikov has put together a guide to applying LangChain, LangGraph, and Large Language Models (LLMs) across life sciences, chemistry, biology, drug discovery, and healthcare üß™ Check out the notebooks & exercises here: https://lnkd.in/gV373k2D Images: None Post 30: Announcing LangChain Labs‚Äô newest product: Open SWE Open SWE is an open-source, cloud-based asynchronous coding agent. We've been using Open SWE internally with great success. It's one of the top contributions in our open source repos, and its own repo! Try it out today, just provide an Anthropic API key: https://swe.langchain.com Or, you can fork the repo and deploy it yourself: https://lnkd.in/grP2g2PM Open SWE performs best on long running, complex tasks thanks to its specialized planning and reviewing agents that run before & after the programmer. It runs in a Daytona sandbox, allowing it to run unsupervised, without the risk of it taking malicious actions on your computer. We've also released a YouTube video going over the basics: https://lnkd.in/gfZsrw9s And a blog post: https://lnkd.in/g9FVj6yH I'm super excited to see this get released, and can't wait to ship more features to it! Images: https://media.licdn.com/dms/image/v2/D5622AQHC6zR8Ry5lCQ/feedshare-shrink_800/B56ZiAYTIrHkAg-/0/1754500511010?e=1764201600&v=beta&t=01oNWCbd8l3j-l9EZ7Ghd0lDeSamhHcJCVRqgkmGmh0 Post 31: ü¶úDeep Agents <> MCP Added a section to the Deep Agent docs on how to use them MCPs This lets you set up an agent that can plan and act over longer time horizons and can also connect to arbitrary services Docs: https://lnkd.in/g2EaYy6r Images: https://media.licdn.com/dms/image/v2/D5622AQHPSGCNdyfwXA/feedshare-shrink_800/B56ZiAoAlVHUAs-/0/1754504629640?e=1764201600&v=beta&t=KhbFzgm22nWRZ8cuuNFw0m0dU-PyScXX5nWag3CclTI Post 32: Resharing Ben Liebald ‚Äôs talk from Interrupt given the $100M ARR milestone announcement today‚Ä¶ Congrats Harvey team! Images: https://media.licdn.com/dms/image/v2/D4E22AQFMVxTwNnXiiw/feedshare-shrink_800/B4EZdgKe0hG4Ak-/0/1749665051279?e=1764201600&v=beta&t=9vq9p-aWvh_vfW8Nb2h8A_XbVvmyOOLQGg1mizGEP20 Post 33: üëêUse gpt-oss with `deepagents` Deep Agents require good tool calling capabilities... something that OpenAI's new open source model is pretty good at Thanks to Ryan Eggleston for adding an example how to use gpt-oss (via Ollama ) to `deepagents` Docs: https://lnkd.in/g9akd5YN Images: https://media.licdn.com/dms/image/v2/D5622AQGwWgIhb3GpYg/feedshare-shrink_2048_1536/B56Zh7U4m_H0As-/0/1754415729768?e=1764201600&v=beta&t=9nQKFttRAw-S_K6NQksNM03O4Vrw3lw8JlTGbtOAeCQ Post 34: ü¶úüéôÔ∏èLangChain Academy LIVE We've been investing a lot in online education, but recently we decided to try something new On August 19th in SF we are bringing ~60 agent builders together for a live "ambient agent" workshop Sign upüëâ https://lnkd.in/ggi6QTqq Images: https://media.licdn.com/dms/image/v2/D5622AQGfYUE48B9g4A/feedshare-shrink_800/B56Zh3FvBdHcAo-/0/1754344649917?e=1764201600&v=beta&t=j4F15SAgucDEPQK7RGKKTeEa1Thi5BDbm8Bl00RLTJ0 Post 35: ü¶ú Langgraph + MCP ü§ñ There are two main ways you can point LangChain 's Langgraph framework at MCP servers. For both, first create an MCP client pointing at the MCP servers: client = MultiServerMCPClient({ "itinerary": { "url": "http://localhost:8000/mcp/", "transport": "streamable_http", }}) Then either: 1) Use the prebuilt react agent from langgraph.prebuilt: tools = await client.get_tools() agent = create_react_agent(model, tools) hotel_response = await agent.ainvoke({"messages": "Find me a hotel in SF for 2 nights starting from 2024-01-01 with WiFi and pool."}) 2) Set up the entire graph yourself, so that you have full control on the flow: tools = await client.get_tools() def call_model(state: MessagesState): response = model.bind_tools(tools).invoke(state["messages"]) return {"messages": response} builder = StateGraph(MessagesState) builder.add_node(call_model) builder.add_node(ToolNode(tools)) builder.add_edge(START, "call_model") builder.add_conditional_edges( "call_model", tools_condition, ) builder.add_edge("tools", "call_model") graph = builder.compile() hotel_response = await graph.ainvoke({"messages": "Find me a hotel in SF for 2 nights starting from 2024-01-01 with WiFI and pool."}) See full examples here, which include model configuration for either Azure OpenAI or GitHub Models: https://lnkd.in/gHxXDvwy https://lnkd.in/ghU5snwK See docs for langchain-mcp-adapters here: Images: https://media.licdn.com/dms/image/v2/D5622AQHG45waD0sygw/feedshare-shrink_800/B56ZhSsILTHkAk-/0/1753733956609?e=1764201600&v=beta&t=vYqSEn3MCzsfjHAZ-Rzs0yIt8O2mWax9aW_yWLoBH1g, https://media.licdn.com/dms/image/v2/D5622AQHmczNxlwNJmg/feedshare-shrink_800/B56ZhSsIMiHMAg-/0/1753733957124?e=1764201600&v=beta&t=AlmFr-MKNx1z_92MhJ63PSnwoHT-JbzV_rGJda9H0YE